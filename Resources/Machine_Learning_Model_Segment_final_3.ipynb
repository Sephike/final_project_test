{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing our dependencies\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from config import db_password\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "import time\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to the SQL Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials = f\"postgres://postgres:{db_password}@127.0.0.1:5432/video_game\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connection parameters, yours will be different\n",
    "# params_dic = {\n",
    "#     \"host\"      : \"localhost\",\n",
    "#     \"database\"  : \"video_game\",\n",
    "#     \"port\"      : 5432,\n",
    "#     \"user\"      : \"postgres\",\n",
    "#     \"password\"  : db_password\n",
    "# }\n",
    "def connect(credentials):\n",
    "    \"\"\" Connect to the PostgreSQL database server \"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        # connect to the PostgreSQL server\n",
    "        print('Connecting to the PostgreSQL database...')\n",
    "        conn = psycopg2.connect(credentials)\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "#         sys.exit(1) \n",
    "    print(\"Connection successful\")\n",
    "    return conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A function to conect a db and bring in Data into a panda df \n",
    "def postgresql_to_dataframe(conn, select_query, column_names):\n",
    "    \"\"\"\n",
    "    Tranform a SELECT query into a pandas dataframe\n",
    "    \"\"\"\n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        cursor.execute(select_query)\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(\"Error: %s\" % error)\n",
    "        cursor.close()\n",
    "        return 1\n",
    "    \n",
    "    # Naturally we get a list of tupples\n",
    "    tupples = cursor.fetchall()\n",
    "    cursor.close()\n",
    "    \n",
    "    # We just need to turn it into a pandas dataframe\n",
    "    df = pd.DataFrame(tupples, columns=column_names)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the PostgreSQL database...\n",
      "FATAL:  password authentication failed for user \"postgres\"\n",
      "\n",
      "Connection successful\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'cursor'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-300da4413d8a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcolumn_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"rank\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"name\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"year\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"genre\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"na_sales\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"eu_sales\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"jp_sales\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"other_sales\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"global_sales\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Critic_Score\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"ESRB_Rating\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"userscore\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"metascore\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Execute the \"SELECT *\" query\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpostgresql_to_dataframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"select * from final_vg_data\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-aad6359e2158>\u001b[0m in \u001b[0;36mpostgresql_to_dataframe\u001b[1;34m(conn, select_query, column_names)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mTranform\u001b[0m \u001b[0ma\u001b[0m \u001b[0mSELECT\u001b[0m \u001b[0mquery\u001b[0m \u001b[0minto\u001b[0m \u001b[0ma\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \"\"\"\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mcursor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mcursor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mselect_query\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'cursor'"
     ]
    }
   ],
   "source": [
    "# Connect to the database\n",
    "conn = connect(credentials)\n",
    "column_names = [\"rank\",\"name\",\"year\",\"genre\",\"na_sales\",\"eu_sales\",\"jp_sales\",\"other_sales\",\"global_sales\",\"Critic_Score\",\"ESRB_Rating\",\"userscore\",\"metascore\"]\n",
    "# Execute the \"SELECT *\" query\n",
    "df = postgresql_to_dataframe(conn, \"select * from final_vg_data\", column_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created the genre dataframe to hold all the genres as columns\n",
    "\n",
    "genre_dummy = pd.get_dummies(df['genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropped the genre column\n",
    "\n",
    "df.drop(columns=[\"genre\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifiying our data\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To allow us to see all columns in the head of the dataframe\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaled the metascore to match user_score and Critic_score\n",
    "\n",
    "df['metascore']=df['metascore']/10\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Made esrb a dataframe to hold all the ratings as columns\n",
    "\n",
    "ESRB_Rating_dummy = pd.get_dummies(df['ESRB_Rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropped esrb_rating\n",
    "\n",
    "df.drop(columns=[\"ESRB_Rating\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the original dataframe with the dummy\n",
    "\n",
    "df_dummy = pd.concat([df,genre_dummy,ESRB_Rating_dummy], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping any NaN values\n",
    "\n",
    "df_dummy = df_dummy.dropna() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying Null in Data \n",
    "df_dummy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping unnecessary columns\n",
    "\n",
    "df_dummy.drop(columns=[\"Critic_Score\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identifying Null in Data\n",
    "\n",
    "df_dummy.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing seaborn plots to identify possible variables to test\n",
    "\n",
    "import seaborn as sns\n",
    "sns.pairplot(df_dummy[['rank', 'name', 'year', 'na_sales', 'eu_sales', 'jp_sales',\n",
    "       'other_sales', 'global_sales', 'userscore',\n",
    "       'metascore']], diag_kind='kde')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metascore and na sales linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The target variable is NA_Sales, Global_Sales in the linear regression model \n",
    "plt.scatter(df_dummy[\"metascore\"], df_dummy[\"na_sales\"])\n",
    "plt.xlabel('metascore')\n",
    "plt.ylabel('na_sales')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set X equal to the metascore column\n",
    "X = df_dummy[\"metascore\"].values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Examine the first five entries in X\n",
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#examine the shape of X\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target variable, or the Global_Sales column\n",
    "y = df_dummy.na_sales.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training/test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an instance of the linear regression model\n",
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting or training the Model \n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the model will predict the Model\n",
    "y_pred = model.predict(X)\n",
    "print(y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predictions for years of experience\n",
    "plt.scatter(X, y)\n",
    "plt.plot(X, y_pred, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#examine the specific parameters of our model: the slope and the y-intercept. The slope is represented by model.coef_, and model.intercept_ is the y-intercept:\n",
    "print(model.coef_)\n",
    "print(model.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the Labels and Data from the Model \n",
    "print(f\"Labels: {y[:10]}\")\n",
    "print(f\"Data: {X[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\" % np.mean((model.predict(X) - y) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % model.score(X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metascore and Userscore linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set X equal to the metascore column\n",
    "X = df_dummy[\"metascore\"].values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Examine the first five entries in X\n",
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#examine the shape of X\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target variable, or the user_score column\n",
    "y = df_dummy.userscore.values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an instance of the linear regression model\n",
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting or training the Model \n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the model will predict the Model\n",
    "y_pred = model.predict(X)\n",
    "print(y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predictions for years of experience\n",
    "plt.scatter(X, y)\n",
    "plt.plot(X, y_pred, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#examine the specific parameters of our model: the slope and the y-intercept. The slope is represented by model.coef_, and model.intercept_ is the y-intercept:\n",
    "print(model.coef_)\n",
    "print(model.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the Labels and Data from the Model \n",
    "print(f\"Labels: {y[:10]}\")\n",
    "print(f\"Data: {X[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The mean squared error for metascore and userscore\n",
    "print(\"Mean squared error: %.2f\" % np.mean((model.predict(X) - y) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % model.score(X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set X equal to 'E', 'E10', 'M', 'RP', 'T', 'Action', 'Adventure', 'Fighting', 'Misc', 'Platform', 'Puzzle', 'Racing', 'Role-Playing', 'Shooter', 'Simulation', 'Sports', 'Strategy'\n",
    "X = df_dummy[['E', 'E10', 'M', 'RP', 'T', 'Action', 'Adventure', 'Fighting', 'Misc', 'Platform', 'Puzzle', 'Racing', 'Role-Playing', 'Shooter', 'Simulation', 'Sports', 'Strategy']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target variable, or the na_sales column\n",
    "y = df_dummy.na_sales.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training/test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random forest classifier.\n",
    "rf_model = RandomForestRegressor(n_estimators=122, random_state=42)\n",
    "\n",
    "# Fitting the model\n",
    "rf_model = rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = rf_model.predict(X_test_scaled)\n",
    "rf_model.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the r2 score\n",
    "r2_score(y_pred, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
